{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9069ae86-29f3-4eb8-af22-cb46126bdb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "206f61ae-b72f-4f49-a360-f5ee5e1b6bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust if your paths differ\n",
    "PANECHO_ROOT = \"/home/users/joshua04/141/PanEcho\"\n",
    "DATA_ROOT = \"/home/users/joshua04/141/data/raw/echonet_pediatric/A4C\"\n",
    "\n",
    "sys.path.append(PANECHO_ROOT)\n",
    "sys.path.append(os.path.join(PANECHO_ROOT, \"src\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e0f4f7d-d483-4400-9d61-7fd1620e394e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/joshua04/141/torch-gpu/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.models import FrameTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5104cc99-04c2-46fb-b9f3-ac7053025b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1e3d2a8-b48c-41ec-ac97-3a03cd01d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video_frames(path, n_frames=16):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Could not open video: {path}\")\n",
    "\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    idxs = np.linspace(0, max(length - 1, 0), n_frames).astype(int)\n",
    "\n",
    "    frames = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        if i in idxs:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(transform(frame))\n",
    "        i += 1\n",
    "    cap.release()\n",
    "    while len(frames) < n_frames:\n",
    "        frames.append(frames[-1])\n",
    "\n",
    "    return torch.stack(frames, dim=1)  # (3, T, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f9f4c1-fef8-48ab-ba81-5442fd76f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EchoNetVideoDataset(Dataset):\n",
    "    def __init__(self, root, split=\"train\", n_frames=16):\n",
    "        df = pd.read_csv(os.path.join(root, \"FileList.csv\"))\n",
    "        df = df[df[\"Split\"] != 5] if split == \"train\" else df[df[\"Split\"] == 5]\n",
    "\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root = root\n",
    "        self.n_frames = n_frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        path = os.path.join(self.root, \"Videos\", row[\"FileName\"])\n",
    "        x = read_video_frames(path, self.n_frames)\n",
    "        y = torch.tensor(row[\"EF\"], dtype=torch.float32)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efed9d83-681d-450e-87a7-df568b18c9bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    EchoNetVideoDataset(DATA_ROOT, split=\"train\"),\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "    prefetch_factor=2)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    EchoNetVideoDataset(DATA_ROOT, split=\"val\"),\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "    prefetch_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0da5afa5-8652-46c5-b6fe-2e4c7c61c56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): FrameTransformer(\n",
      "    (encoder): ImageEncoder(\n",
      "      (model): ConvNeXt(\n",
      "        (features): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "            (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=96, out_features=384, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=384, out_features=96, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "            )\n",
      "            (1): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=96, out_features=384, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=384, out_features=96, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)\n",
      "            )\n",
      "            (2): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=96, out_features=384, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=384, out_features=96, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)\n",
      "            )\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "            (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
      "          )\n",
      "          (3): Sequential(\n",
      "            (0): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=192, out_features=768, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)\n",
      "            )\n",
      "            (1): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=192, out_features=768, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)\n",
      "            )\n",
      "            (2): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=192, out_features=768, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)\n",
      "            )\n",
      "          )\n",
      "          (4): Sequential(\n",
      "            (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
      "            (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "          )\n",
      "          (5): Sequential(\n",
      "            (0): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)\n",
      "            )\n",
      "            (1): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)\n",
      "            )\n",
      "            (2): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)\n",
      "            )\n",
      "            (3): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)\n",
      "            )\n",
      "            (4): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)\n",
      "            )\n",
      "            (5): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)\n",
      "            )\n",
      "            (6): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)\n",
      "            )\n",
      "            (7): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)\n",
      "            )\n",
      "            (8): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)\n",
      "            )\n",
      "          )\n",
      "          (6): Sequential(\n",
      "            (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "          )\n",
      "          (7): Sequential(\n",
      "            (0): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)\n",
      "            )\n",
      "            (1): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)\n",
      "            )\n",
      "            (2): CNBlock(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "                (1): Permute()\n",
      "                (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "                (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (4): GELU(approximate='none')\n",
      "                (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (6): Permute()\n",
      "              )\n",
      "              (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (classifier): Sequential(\n",
      "          (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (1): Flatten(start_dim=1, end_dim=-1)\n",
      "          (2): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transformer): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (classifier): Identity()\n",
      "    (time_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=768, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "backbone = FrameTransformer(\n",
    "    arch=\"convnext_tiny\",\n",
    "    n_heads=8,\n",
    "    n_layers=2,\n",
    "    transformer_dropout=0.1,\n",
    "    pooling=\"mean\",\n",
    "    clip_len=16)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    backbone,\n",
    "    nn.Linear(768, 1)).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3489702c-3cd5-464b-ab3b-5012205e3820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters:\n",
      "  1.weight\n",
      "  1.bias\n"
     ]
    }
   ],
   "source": [
    "for p in model[0].parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "for p in model[1].parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "print(\"Trainable parameters:\")\n",
    "for name, p in model.named_parameters():\n",
    "    if p.requires_grad:\n",
    "        print(\" \", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94e7527c-02b2-4d96-9e71-050cbaa8daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()   # EF regression\n",
    "optimizer = optim.AdamW(\n",
    "    model[1].parameters(),\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4)\n",
    "\n",
    "use_amp = (device == \"cuda\")\n",
    "scaler = torch.amp.GradScaler(\"cuda\", enabled=use_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc1c0596-61c3-4b1f-ab6d-d3ed9605f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_epoch(model, loader, train=True):\n",
    "    model.train(train)\n",
    "    total_loss = 0.0\n",
    "    total = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device).view(-1, 1)\n",
    "        if train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(\"cuda\", enabled=use_amp):\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "        if train:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        total += x.size(0)\n",
    "    return total_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "977933e9-0f64-43ed-88b5-9c1c51c79da7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 | train MSE: 249.7169 | val MSE: 151.1278\n",
      "  âœ“ Saved new best model (val MSE = 151.1278)\n",
      "Epoch 01 | train MSE: 90.5181 | val MSE: 148.4066\n",
      "  âœ“ Saved new best model (val MSE = 148.4066)\n",
      "Epoch 02 | train MSE: 84.9801 | val MSE: 125.4066\n",
      "  âœ“ Saved new best model (val MSE = 125.4066)\n",
      "Epoch 03 | train MSE: 81.4717 | val MSE: 119.6045\n",
      "  âœ“ Saved new best model (val MSE = 119.6045)\n",
      "Epoch 04 | train MSE: 78.7430 | val MSE: 121.4391\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "num_epochs = 5\n",
    "best_val_loss = float(\"inf\")\n",
    "best_path = \"/home/users/joshua04/141/results/ef_best.pt\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # ðŸ”“ Unfreeze backbone after 5 epochs\n",
    "    if epoch == 5:\n",
    "        print(\"Unfreezing backbone...\")\n",
    "        for p in model[0].parameters():\n",
    "            p.requires_grad = True\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=1e-5,          # lower LR for fine-tuning\n",
    "            weight_decay=1e-4)\n",
    "    train_loss = run_one_epoch(model, train_loader, train=True)\n",
    "    val_loss   = run_one_epoch(model, val_loader,   train=False)\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"train MSE: {train_loss:.4f} | \"\n",
    "        f\"val MSE: {val_loss:.4f}\")\n",
    "    # ðŸ’¾ Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "        print(f\"  âœ“ Saved new best model (val MSE = {val_loss:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2bc13f9-fa89-4839-be8a-fd8ca642e469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 76.991\n",
      "val   loss: 132.564\n"
     ]
    }
   ],
   "source": [
    "train_loss = run_one_epoch(model, train_loader, train=True)\n",
    "val_loss   = run_one_epoch(model, val_loader,   train=False)\n",
    "\n",
    "print(f\"train loss: {train_loss:.3f}\")\n",
    "print(f\"val   loss: {val_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bd3a878-f812-4fa0-bb66-b1d12f6a4b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /home/users/joshua04/141/results/ef_finetuned.pt\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/home/users/joshua04/141/results/ef_finetuned.pt\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(\"Saved to:\", save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (GPU)",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
