{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a68ac447-2ec6-4668-aa8f-bf10e62be48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.13.0.90-cp37-abi3-manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=2 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from opencv-python) (2.3.5)\n",
      "Downloading opencv_python-4.13.0.90-cp37-abi3-manylinux_2_28_x86_64.whl (72.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.13.0.90\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bc51978-fe72-404a-973d-0737527c1b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# ---------- video transform ----------\n",
    "transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "def read_video(path, n_frames=16):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    idxs = np.linspace(0, max(length - 1, 0), n_frames).astype(int)\n",
    "\n",
    "    frames = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        if i in idxs:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(transform(frame))\n",
    "        i += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # pad if video shorter than n_frames\n",
    "    while len(frames) < n_frames:\n",
    "        frames.append(frames[-1])\n",
    "\n",
    "    return torch.stack(frames, dim=1)  # (3, T, 224, 224)\n",
    "\n",
    "\n",
    "# ---------- Dataset ----------\n",
    "class EchoNetA4C(Dataset):\n",
    "    def __init__(self, root, split=\"train\", n_frames=16):\n",
    "        self.root = root\n",
    "        self.n_frames = n_frames\n",
    "\n",
    "        df = pd.read_csv(os.path.join(root, \"FileList.csv\"))\n",
    "\n",
    "        if split == \"train\":\n",
    "            df = df[df[\"Split\"] != 5]\n",
    "        else:\n",
    "            df = df[df[\"Split\"] == 5]\n",
    "\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        video_path = os.path.join(self.root, \"Videos\", row[\"FileName\"])\n",
    "\n",
    "        x = read_video(video_path, self.n_frames)\n",
    "        y = torch.tensor(row[\"EF\"], dtype=torch.float32)\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1bb6709-17f5-4906-8665-68e51cee7788",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = EchoNetA4C(\n",
    "    \"/home/users/joshua04/141/data/raw/echonet_pediatric/A4C\",\n",
    "    split=\"train\",\n",
    "    n_frames=16\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c801b7f-28ad-4a94-b440-61a1b9799778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.5.1+cu121\n",
      "cuda available: True\n",
      "GPU: NVIDIA L40S\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4ba7156-31ba-43f5-ad85-a083ac22db97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:\n",
      "/home/users/joshua04/141\n",
      "\n",
      "Files in this directory:\n",
      "['Untitled3.ipynb', '.ipynb_checkpoints']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Current working directory:\")\n",
    "print(os.getcwd())\n",
    "\n",
    "print(\"\\nFiles in this directory:\")\n",
    "print(os.listdir(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77595dcf-14ba-42d0-86da-9df89d61e388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled3.ipynb  checkpoints  data  results  src\n"
     ]
    }
   ],
   "source": [
    "!cd ~/141\n",
    "!mkdir -p data/raw data/processed src checkpoints results\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "994c8cb3-12cb-4dc5-8512-228b71684189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a1f1358-effe-44b8-94ad-3cd9997cf8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "418a4f33-5bdc-436b-99fd-c8f28ede24c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 3.0.0\n",
      "numpy: 2.3.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e41eba0-88e8-4b5c-9d69-716ed72d0500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists: True\n",
      "Contents: ['Videos', 'FileList.csv', 'FileList_new.csv', 'VolumeTracings_new.csv', 'VolumeTracings.csv']\n",
      "                         FileName     EF Sex  Age  Weight  Height  Split\n",
      "0  CR32a7555-CR32a7582-000039.avi  40.83   F    0    10.2    68.5      5\n",
      "1  CR32a7555-CR32a97af-000033.avi  52.62   F    1    15.5    85.0      5\n",
      "2  CR32a7555-CR32a97e1-000024.avi  24.85   F    0     4.0    56.0      5\n",
      "3  CR32a7555-CR32a9850-000040.avi  50.96   F    4    18.0    99.0      5\n",
      "4  CR32a7555-CR32a988d-000034.avi  56.76   F    0    13.2    75.0      5\n",
      "Number of A4C studies: 3284\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_ROOT = \"/home/users/joshua04/141/data/raw/echonet_pediatric/A4C\"\n",
    "\n",
    "print(\"Exists:\", os.path.exists(DATA_ROOT))\n",
    "print(\"Contents:\", os.listdir(DATA_ROOT))\n",
    "\n",
    "filelist = pd.read_csv(os.path.join(DATA_ROOT, \"FileList.csv\"))\n",
    "print(filelist.head())\n",
    "print(\"Number of A4C studies:\", len(filelist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "041e0d81-a16a-4729-bd1c-bc9536639e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-1.0.24-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: torch in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from timm) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from timm) (0.20.1+cu121)\n",
      "Collecting pyyaml (from timm)\n",
      "  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting huggingface_hub (from timm)\n",
      "  Downloading huggingface_hub-1.3.4-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors (from timm)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: filelock in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from huggingface_hub->timm) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from huggingface_hub->timm) (2025.12.0)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface_hub->timm)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from huggingface_hub->timm)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from huggingface_hub->timm) (26.0)\n",
      "Collecting shellingham (from huggingface_hub->timm)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting tqdm>=4.42.1 (from huggingface_hub->timm)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typer-slim (from huggingface_hub->timm)\n",
      "  Downloading typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from huggingface_hub->timm) (4.15.0)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->huggingface_hub->timm)\n",
      "  Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->huggingface_hub->timm)\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->huggingface_hub->timm)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1,>=0.23.0->huggingface_hub->timm)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->timm)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: networkx in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from torch->timm) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from torch->timm) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from torch->timm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from torch->timm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from torch->timm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from torch->timm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from torch->timm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from torch->timm) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from torch->timm) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from torch->timm) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.9.86)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from jinja2->torch->timm) (2.1.5)\n",
      "Requirement already satisfied: numpy in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from torchvision->timm) (2.3.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/users/joshua04/torch-gpu/lib/python3.12/site-packages (from torchvision->timm) (12.0.0)\n",
      "Collecting click>=8.0.0 (from typer-slim->huggingface_hub->timm)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading timm-1.0.24-py3-none-any.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-1.3.4-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Installing collected packages: tqdm, shellingham, safetensors, pyyaml, idna, hf-xet, h11, click, certifi, typer-slim, httpcore, anyio, httpx, huggingface_hub, timm\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [timm]2m14/15\u001b[0m [timm]ngface_hub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed anyio-4.12.1 certifi-2026.1.4 click-8.3.1 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface_hub-1.3.4 idna-3.11 pyyaml-6.0.3 safetensors-0.7.0 shellingham-1.5.4 timm-1.0.24 tqdm-4.67.1 typer-slim-0.21.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a57fdba2-20bc-4b9c-b7f5-908a8ffcbbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# ---------- video transform ----------\n",
    "transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "def read_video(path, n_frames=16):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    idxs = np.linspace(0, max(length - 1, 0), n_frames).astype(int)\n",
    "\n",
    "    frames = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        if i in idxs:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(transform(frame))\n",
    "        i += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    while len(frames) < n_frames:\n",
    "        frames.append(frames[-1])\n",
    "\n",
    "    return torch.stack(frames, dim=1)  # (3, T, 224, 224)\n",
    "\n",
    "\n",
    "class EchoNetA4C(Dataset):\n",
    "    def __init__(self, root, split=\"train\", n_frames=16):\n",
    "        self.root = root\n",
    "        self.n_frames = n_frames\n",
    "\n",
    "        df = pd.read_csv(os.path.join(root, \"FileList.csv\"))\n",
    "        df = df[df[\"Split\"] != 5] if split == \"train\" else df[df[\"Split\"] == 5]\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        path = os.path.join(self.root, \"Videos\", row[\"FileName\"])\n",
    "        x = read_video(path, self.n_frames)\n",
    "        y = torch.tensor(row[\"EF\"], dtype=torch.float32)\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e75f5047-598d-4d0c-9e08-92a3bdc52add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader batches: 1466\n"
     ]
    }
   ],
   "source": [
    "train_ds = EchoNetA4C(\n",
    "    \"/home/users/joshua04/141/data/raw/echonet_pediatric/A4C\",\n",
    "    split=\"train\",\n",
    "    n_frames=16\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"train_loader batches:\", len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6620e0b-e0ca-4fa0-92ff-703022cb213d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/joshua04/torch-gpu/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PanEcho ready on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load(\n",
    "    \"/home/users/joshua04/141/PanEcho\",\n",
    "    \"PanEcho\",\n",
    "    source=\"local\"\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"PanEcho ready on\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba659f66-a76d-4964-9bef-1e33c12c0d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pericardial-effusion', 'EF', 'GLS', 'LVEDV', 'LVESV', 'LVSV', 'LVSize', 'LVWallThickness-increased-any', 'LVWallThickness-increased-modsev', 'LVSystolicFunction', 'LVWallMotionAbnormalities', 'IVSd', 'LVPWd', 'LVIDs', 'LVIDd', 'LVOTDiam', 'LVDiastolicFunction', 'E|EAvg', 'RVSP', 'RVSize', 'RVSystolicFunction', 'RVIDd', 'TAPSE', 'RVSVel', 'LASize', 'LAIDs2D', 'LAVol', 'RASize', 'RADimensionM-L(cm)', 'AVStructure', 'AVStenosis', 'AVPkVel(m|s)', 'AVRegurg', 'LVOT20mmHg', 'MVStenosis', 'MVRegurgitation', 'TVRegurgitation', 'TVPkGrad', 'RAP-8-or-higher', 'AORoot'])\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x = x.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(x)\n",
    "\n",
    "print(out.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1ec8da3-9dd5-46a2-b6bc-1aa3d9a693b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pericardial-effusion torch.Size([2, 1])\n",
      "EF torch.Size([2, 1])\n",
      "GLS torch.Size([2, 1])\n",
      "LVEDV torch.Size([2, 1])\n",
      "LVESV torch.Size([2, 1])\n",
      "LVSV torch.Size([2, 1])\n",
      "LVSize torch.Size([2, 3])\n",
      "LVWallThickness-increased-any torch.Size([2, 1])\n",
      "LVWallThickness-increased-modsev torch.Size([2, 1])\n",
      "LVSystolicFunction torch.Size([2, 3])\n",
      "LVWallMotionAbnormalities torch.Size([2, 1])\n",
      "IVSd torch.Size([2, 1])\n",
      "LVPWd torch.Size([2, 1])\n",
      "LVIDs torch.Size([2, 1])\n",
      "LVIDd torch.Size([2, 1])\n",
      "LVOTDiam torch.Size([2, 1])\n",
      "LVDiastolicFunction torch.Size([2, 3])\n",
      "E|EAvg torch.Size([2, 1])\n",
      "RVSP torch.Size([2, 1])\n",
      "RVSize torch.Size([2, 3])\n",
      "RVSystolicFunction torch.Size([2, 1])\n",
      "RVIDd torch.Size([2, 1])\n",
      "TAPSE torch.Size([2, 1])\n",
      "RVSVel torch.Size([2, 1])\n",
      "LASize torch.Size([2, 3])\n",
      "LAIDs2D torch.Size([2, 1])\n",
      "LAVol torch.Size([2, 1])\n",
      "RASize torch.Size([2, 1])\n",
      "RADimensionM-L(cm) torch.Size([2, 1])\n",
      "AVStructure torch.Size([2, 1])\n",
      "AVStenosis torch.Size([2, 3])\n",
      "AVPkVel(m|s) torch.Size([2, 1])\n",
      "AVRegurg torch.Size([2, 3])\n",
      "LVOT20mmHg torch.Size([2, 1])\n",
      "MVStenosis torch.Size([2, 1])\n",
      "MVRegurgitation torch.Size([2, 3])\n",
      "TVRegurgitation torch.Size([2, 3])\n",
      "TVPkGrad torch.Size([2, 1])\n",
      "RAP-8-or-higher torch.Size([2, 1])\n",
      "AORoot torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "for k, v in out.items():\n",
    "    print(k, v.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e651a00-d348-4518-b70a-d56ef8b1521a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 63.52 | True: 60.61\n",
      "Pred: 59.32 | True: 52.92\n"
     ]
    }
   ],
   "source": [
    "ef_pred = out[\"EF\"].squeeze().cpu()\n",
    "ef_true = y[:len(ef_pred)]\n",
    "\n",
    "for i in range(min(5, len(ef_pred))):\n",
    "    print(f\"Pred: {ef_pred[i].item():.2f} | True: {ef_true[i].item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8a9a1fd-6093-4731-8fb0-2793d84d6c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device count: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (GPU)",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
